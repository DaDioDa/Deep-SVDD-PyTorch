{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from deepSVDD import DeepSVDD\n",
    "from datasets.main import load_dataset\n",
    "from base.base_dataset import BaseADDataset\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.combine import SMOTEENN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        \"\"\"\n",
    "        初始化 Dataset\n",
    "        :param data: 已處理的特徵數據 (NumPy array or Pandas DataFrame)\n",
    "        :param labels: 對應的標籤數據\n",
    "        \"\"\"\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"返回數據集大小\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"根據索引返回一筆數據及其標籤\"\"\"\n",
    "        return self.data[idx], self.labels[idx], idx\n",
    "\n",
    "class MyADDataset(BaseADDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(r'multiclass15\\csv_result-data1 Sampled Scenarios.csv')\n",
    "\n",
    "    def process_data(self, file_path):\n",
    "        # 讀取資料\n",
    "        df=pd.read_csv(r'multiclass15\\csv_result-data1 Sampled Scenarios.csv')\n",
    "        for i in range(2, 16):\n",
    "            tmp = pd.read_csv(r'multiclass15\\csv_result-data'+str(i)+' Sampled Scenarios.csv')\n",
    "            df = pd.concat([df, tmp], ignore_index=True)\n",
    "        \n",
    "        # df = pd.read_csv(file_path)\n",
    "        df = df.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        df = df.drop('id', axis=1)\n",
    "        \n",
    "        # 標籤處理\n",
    "        y = df['marker']\n",
    "        y = [0 if value in [41] else 1 for value in y]\n",
    "        X = df.drop('marker', axis=1)\n",
    "\n",
    "        # 刪除不必要的欄位\n",
    "        columns_to_drop = ['control_panel_log1', 'control_panel_log2', 'control_panel_log3', \n",
    "                        'control_panel_log4', 'relay1_log', 'relay2_log', 'relay3_log', \n",
    "                        'relay4_log', 'snort_log1', 'snort_log2', 'snort_log3', 'snort_log4']\n",
    "        X = X.drop(columns=columns_to_drop, axis=1)\n",
    "        \n",
    "        # 分割數據集\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, stratify=y, random_state=42\n",
    "        )\n",
    "\n",
    "        # PCA 降維\n",
    "        # pca = PCA(n_components=15)\n",
    "        # X_train = pca.fit_transform(X_train)\n",
    "        # X_test = pca.transform(X_test)\n",
    "\n",
    "        X_train_df = pd.DataFrame(X_train)\n",
    "        y_train_df = pd.DataFrame(y_train, columns=['label'])\n",
    "\n",
    "        X_train_df.reset_index(drop=True, inplace=True)\n",
    "        y_train_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        merged_df = pd.concat([X_train_df, y_train_df], axis=1)\n",
    "        \n",
    "        label_0_data = merged_df[merged_df['label'] == 0]\n",
    "        train_data = label_0_data.drop('label', axis=1)\n",
    "\n",
    "        # Min-Max 標準化\n",
    "        scaler = MinMaxScaler()\n",
    "        X_train = scaler.fit_transform(train_data)\n",
    "        X_test = scaler.transform(X_test)\n",
    "\n",
    "        return X_train, X_test, y_train, y_test\n",
    "\n",
    "    def create_dataloaders(self, file_path, batch_size=32, num_workers=0):\n",
    "        # 處理數據\n",
    "        X_train, X_test, y_train, y_test = self.process_data(file_path)\n",
    "\n",
    "        # 建立 Dataset\n",
    "        train_dataset = CustomDataset(X_train, y_train)\n",
    "        test_dataset = CustomDataset(X_test, y_test)\n",
    "\n",
    "        # 建立 DataLoader\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "        return train_loader, test_loader\n",
    "    \n",
    "    def loaders(self, batch_size, shuffle_train=True, shuffle_test=False, num_workers = 0):\n",
    "        train_loader, test_loader = self.create_dataloaders(self.root, batch_size=batch_size)\n",
    "        return train_loader, test_loader\n",
    "\n",
    "\n",
    "def test_deep_svdd():\n",
    "    # 隨便填一些測試參數\n",
    "    net_name = 'feature_net'\n",
    "    normal_class = 0\n",
    "    nu = 0.1\n",
    "    objective = 'one-class'\n",
    "    device = 'cuda'\n",
    "\n",
    "    print(\"開始測試 DeepSVDD...\")\n",
    "\n",
    "    # 初始化 DeepSVDD 並設定網路\n",
    "    deep_svdd = DeepSVDD(objective, nu)\n",
    "    deep_svdd.set_network(net_name)\n",
    "\n",
    "    data = MyADDataset()\n",
    "\n",
    "    # 測試 train\n",
    "    print(\"開始訓練...\")\n",
    "    deep_svdd.train(\n",
    "        data,\n",
    "        optimizer_name='adam',\n",
    "        lr=0.001,\n",
    "        n_epochs=150, \n",
    "        lr_milestones=[],\n",
    "        batch_size=64,\n",
    "        weight_decay=1e-6,\n",
    "        device=device,\n",
    "        n_jobs_dataloader=0\n",
    "    )\n",
    "    print(\"訓練完成。\")\n",
    "\n",
    "    # 測試 test\n",
    "    print(\"開始測試...\")\n",
    "    deep_svdd.test(data, device=device, n_jobs_dataloader=0)\n",
    "\n",
    "    print(\"測試完成。\")\n",
    "\n",
    "    return deep_svdd.results, deep_svdd.getNet(), data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "開始測試 DeepSVDD...\n",
      "開始訓練...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Initializing center c...\n",
      "INFO:root:Center c initialized.\n",
      "INFO:root:Starting training...\n",
      "c:\\Users\\user\\AppData\\Local\\anaconda3\\envs\\AnomalyDetectionMLGPU\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:224: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\n",
      "INFO:root:  Epoch 1/150\t Time: 0.114\t Loss: 0.01487293\n",
      "INFO:root:  Epoch 2/150\t Time: 0.097\t Loss: 0.00011832\n",
      "INFO:root:  Epoch 3/150\t Time: 0.085\t Loss: 0.00005353\n",
      "INFO:root:  Epoch 4/150\t Time: 0.083\t Loss: 0.00003915\n",
      "INFO:root:  Epoch 5/150\t Time: 0.080\t Loss: 0.00003013\n",
      "INFO:root:  Epoch 6/150\t Time: 0.072\t Loss: 0.00002494\n",
      "INFO:root:  Epoch 7/150\t Time: 0.067\t Loss: 0.00002054\n",
      "INFO:root:  Epoch 8/150\t Time: 0.062\t Loss: 0.00001732\n",
      "INFO:root:  Epoch 9/150\t Time: 0.064\t Loss: 0.00001507\n",
      "INFO:root:  Epoch 10/150\t Time: 0.064\t Loss: 0.00001276\n",
      "INFO:root:  Epoch 11/150\t Time: 0.064\t Loss: 0.00001111\n",
      "INFO:root:  Epoch 12/150\t Time: 0.066\t Loss: 0.00001041\n",
      "INFO:root:  Epoch 13/150\t Time: 0.065\t Loss: 0.00000918\n",
      "INFO:root:  Epoch 14/150\t Time: 0.064\t Loss: 0.00000811\n",
      "INFO:root:  Epoch 15/150\t Time: 0.063\t Loss: 0.00000776\n",
      "INFO:root:  Epoch 16/150\t Time: 0.063\t Loss: 0.00000757\n",
      "INFO:root:  Epoch 17/150\t Time: 0.063\t Loss: 0.00000737\n",
      "INFO:root:  Epoch 18/150\t Time: 0.066\t Loss: 0.00000692\n",
      "INFO:root:  Epoch 19/150\t Time: 0.063\t Loss: 0.00000617\n",
      "INFO:root:  Epoch 20/150\t Time: 0.066\t Loss: 0.00000610\n",
      "INFO:root:  Epoch 21/150\t Time: 0.066\t Loss: 0.00000599\n",
      "INFO:root:  Epoch 22/150\t Time: 0.062\t Loss: 0.00000571\n",
      "INFO:root:  Epoch 23/150\t Time: 0.065\t Loss: 0.00000549\n",
      "INFO:root:  Epoch 24/150\t Time: 0.065\t Loss: 0.00000519\n",
      "INFO:root:  Epoch 25/150\t Time: 0.065\t Loss: 0.00000484\n",
      "INFO:root:  Epoch 26/150\t Time: 0.066\t Loss: 0.00000455\n",
      "INFO:root:  Epoch 27/150\t Time: 0.064\t Loss: 0.00000423\n",
      "INFO:root:  Epoch 28/150\t Time: 0.065\t Loss: 0.00000399\n",
      "INFO:root:  Epoch 29/150\t Time: 0.062\t Loss: 0.00000409\n",
      "INFO:root:  Epoch 30/150\t Time: 0.061\t Loss: 0.00000435\n",
      "INFO:root:  Epoch 31/150\t Time: 0.063\t Loss: 0.00000462\n",
      "INFO:root:  Epoch 32/150\t Time: 0.062\t Loss: 0.00000493\n",
      "INFO:root:  Epoch 33/150\t Time: 0.063\t Loss: 0.00000415\n",
      "INFO:root:  Epoch 34/150\t Time: 0.063\t Loss: 0.00000379\n",
      "INFO:root:  Epoch 35/150\t Time: 0.063\t Loss: 0.00000372\n",
      "INFO:root:  Epoch 36/150\t Time: 0.066\t Loss: 0.00000394\n",
      "INFO:root:  Epoch 37/150\t Time: 0.060\t Loss: 0.00000390\n",
      "INFO:root:  Epoch 38/150\t Time: 0.061\t Loss: 0.00000376\n",
      "INFO:root:  Epoch 39/150\t Time: 0.063\t Loss: 0.00000346\n",
      "INFO:root:  Epoch 40/150\t Time: 0.063\t Loss: 0.00000317\n",
      "INFO:root:  Epoch 41/150\t Time: 0.064\t Loss: 0.00000300\n",
      "INFO:root:  Epoch 42/150\t Time: 0.063\t Loss: 0.00000299\n",
      "INFO:root:  Epoch 43/150\t Time: 0.064\t Loss: 0.00000313\n",
      "INFO:root:  Epoch 44/150\t Time: 0.066\t Loss: 0.00000321\n",
      "INFO:root:  Epoch 45/150\t Time: 0.063\t Loss: 0.00000328\n",
      "INFO:root:  Epoch 46/150\t Time: 0.064\t Loss: 0.00000347\n",
      "INFO:root:  Epoch 47/150\t Time: 0.063\t Loss: 0.00000280\n",
      "INFO:root:  Epoch 48/150\t Time: 0.062\t Loss: 0.00000243\n",
      "INFO:root:  Epoch 49/150\t Time: 0.062\t Loss: 0.00000227\n",
      "INFO:root:  Epoch 50/150\t Time: 0.064\t Loss: 0.00000202\n",
      "INFO:root:  Epoch 51/150\t Time: 0.063\t Loss: 0.00000192\n",
      "INFO:root:  Epoch 52/150\t Time: 0.066\t Loss: 0.00000187\n",
      "INFO:root:  Epoch 53/150\t Time: 0.062\t Loss: 0.00000218\n",
      "INFO:root:  Epoch 54/150\t Time: 0.060\t Loss: 0.00000255\n",
      "INFO:root:  Epoch 55/150\t Time: 0.061\t Loss: 0.00000271\n",
      "INFO:root:  Epoch 56/150\t Time: 0.060\t Loss: 0.00000268\n",
      "INFO:root:  Epoch 57/150\t Time: 0.062\t Loss: 0.00000201\n",
      "INFO:root:  Epoch 58/150\t Time: 0.062\t Loss: 0.00000141\n",
      "INFO:root:  Epoch 59/150\t Time: 0.061\t Loss: 0.00000135\n",
      "INFO:root:  Epoch 60/150\t Time: 0.062\t Loss: 0.00000200\n",
      "INFO:root:  Epoch 61/150\t Time: 0.061\t Loss: 0.00000201\n",
      "INFO:root:  Epoch 62/150\t Time: 0.062\t Loss: 0.00000258\n",
      "INFO:root:  Epoch 63/150\t Time: 0.068\t Loss: 0.00000277\n",
      "INFO:root:  Epoch 64/150\t Time: 0.069\t Loss: 0.00000164\n",
      "INFO:root:  Epoch 65/150\t Time: 0.061\t Loss: 0.00000161\n",
      "INFO:root:  Epoch 66/150\t Time: 0.061\t Loss: 0.00000192\n",
      "INFO:root:  Epoch 67/150\t Time: 0.062\t Loss: 0.00000166\n",
      "INFO:root:  Epoch 68/150\t Time: 0.065\t Loss: 0.00000165\n",
      "INFO:root:  Epoch 69/150\t Time: 0.060\t Loss: 0.00000155\n",
      "INFO:root:  Epoch 70/150\t Time: 0.061\t Loss: 0.00000185\n",
      "INFO:root:  Epoch 71/150\t Time: 0.061\t Loss: 0.00000200\n",
      "INFO:root:  Epoch 72/150\t Time: 0.063\t Loss: 0.00000130\n",
      "INFO:root:  Epoch 73/150\t Time: 0.062\t Loss: 0.00000112\n",
      "INFO:root:  Epoch 74/150\t Time: 0.063\t Loss: 0.00000133\n",
      "INFO:root:  Epoch 75/150\t Time: 0.064\t Loss: 0.00000130\n",
      "INFO:root:  Epoch 76/150\t Time: 0.064\t Loss: 0.00000151\n",
      "INFO:root:  Epoch 77/150\t Time: 0.064\t Loss: 0.00000155\n",
      "INFO:root:  Epoch 78/150\t Time: 0.064\t Loss: 0.00000158\n",
      "INFO:root:  Epoch 79/150\t Time: 0.063\t Loss: 0.00000283\n",
      "INFO:root:  Epoch 80/150\t Time: 0.061\t Loss: 0.00000115\n",
      "INFO:root:  Epoch 81/150\t Time: 0.062\t Loss: 0.00000116\n",
      "INFO:root:  Epoch 82/150\t Time: 0.063\t Loss: 0.00000097\n",
      "INFO:root:  Epoch 83/150\t Time: 0.065\t Loss: 0.00000175\n",
      "INFO:root:  Epoch 84/150\t Time: 0.068\t Loss: 0.00000066\n",
      "INFO:root:  Epoch 85/150\t Time: 0.067\t Loss: 0.00000097\n",
      "INFO:root:  Epoch 86/150\t Time: 0.062\t Loss: 0.00000121\n",
      "INFO:root:  Epoch 87/150\t Time: 0.061\t Loss: 0.00000198\n",
      "INFO:root:  Epoch 88/150\t Time: 0.063\t Loss: 0.00000107\n",
      "INFO:root:  Epoch 89/150\t Time: 0.061\t Loss: 0.00000089\n",
      "INFO:root:  Epoch 90/150\t Time: 0.062\t Loss: 0.00000102\n",
      "INFO:root:  Epoch 91/150\t Time: 0.063\t Loss: 0.00000081\n",
      "INFO:root:  Epoch 92/150\t Time: 0.063\t Loss: 0.00000093\n",
      "INFO:root:  Epoch 93/150\t Time: 0.060\t Loss: 0.00000286\n",
      "INFO:root:  Epoch 94/150\t Time: 0.066\t Loss: 0.00000138\n",
      "INFO:root:  Epoch 95/150\t Time: 0.063\t Loss: 0.00000076\n",
      "INFO:root:  Epoch 96/150\t Time: 0.062\t Loss: 0.00000050\n",
      "INFO:root:  Epoch 97/150\t Time: 0.064\t Loss: 0.00000076\n",
      "INFO:root:  Epoch 98/150\t Time: 0.064\t Loss: 0.00000102\n",
      "INFO:root:  Epoch 99/150\t Time: 0.064\t Loss: 0.00000126\n",
      "INFO:root:  Epoch 100/150\t Time: 0.065\t Loss: 0.00000129\n",
      "INFO:root:  Epoch 101/150\t Time: 0.062\t Loss: 0.00000068\n",
      "INFO:root:  Epoch 102/150\t Time: 0.062\t Loss: 0.00000081\n",
      "INFO:root:  Epoch 103/150\t Time: 0.062\t Loss: 0.00000078\n",
      "INFO:root:  Epoch 104/150\t Time: 0.062\t Loss: 0.00000074\n",
      "INFO:root:  Epoch 105/150\t Time: 0.066\t Loss: 0.00000069\n",
      "INFO:root:  Epoch 106/150\t Time: 0.065\t Loss: 0.00000114\n",
      "INFO:root:  Epoch 107/150\t Time: 0.063\t Loss: 0.00000105\n",
      "INFO:root:  Epoch 108/150\t Time: 0.063\t Loss: 0.00000086\n",
      "INFO:root:  Epoch 109/150\t Time: 0.064\t Loss: 0.00000066\n",
      "INFO:root:  Epoch 110/150\t Time: 0.063\t Loss: 0.00000054\n",
      "INFO:root:  Epoch 111/150\t Time: 0.061\t Loss: 0.00000107\n",
      "INFO:root:  Epoch 112/150\t Time: 0.063\t Loss: 0.00000136\n",
      "INFO:root:  Epoch 113/150\t Time: 0.063\t Loss: 0.00000086\n",
      "INFO:root:  Epoch 114/150\t Time: 0.065\t Loss: 0.00000054\n",
      "INFO:root:  Epoch 115/150\t Time: 0.066\t Loss: 0.00000077\n",
      "INFO:root:  Epoch 116/150\t Time: 0.064\t Loss: 0.00000216\n",
      "INFO:root:  Epoch 117/150\t Time: 0.062\t Loss: 0.00000099\n",
      "INFO:root:  Epoch 118/150\t Time: 0.065\t Loss: 0.00000075\n",
      "INFO:root:  Epoch 119/150\t Time: 0.064\t Loss: 0.00000080\n",
      "INFO:root:  Epoch 120/150\t Time: 0.062\t Loss: 0.00000046\n",
      "INFO:root:  Epoch 121/150\t Time: 0.065\t Loss: 0.00000074\n",
      "INFO:root:  Epoch 122/150\t Time: 0.064\t Loss: 0.00000057\n",
      "INFO:root:  Epoch 123/150\t Time: 0.065\t Loss: 0.00000050\n",
      "INFO:root:  Epoch 124/150\t Time: 0.064\t Loss: 0.00000064\n",
      "INFO:root:  Epoch 125/150\t Time: 0.064\t Loss: 0.00000085\n",
      "INFO:root:  Epoch 126/150\t Time: 0.064\t Loss: 0.00000067\n",
      "INFO:root:  Epoch 127/150\t Time: 0.063\t Loss: 0.00000076\n",
      "INFO:root:  Epoch 128/150\t Time: 0.062\t Loss: 0.00000041\n",
      "INFO:root:  Epoch 129/150\t Time: 0.062\t Loss: 0.00000133\n",
      "INFO:root:  Epoch 130/150\t Time: 0.065\t Loss: 0.00000152\n",
      "INFO:root:  Epoch 131/150\t Time: 0.066\t Loss: 0.00000038\n",
      "INFO:root:  Epoch 132/150\t Time: 0.064\t Loss: 0.00000024\n",
      "INFO:root:  Epoch 133/150\t Time: 0.065\t Loss: 0.00000086\n",
      "INFO:root:  Epoch 134/150\t Time: 0.070\t Loss: 0.00000063\n",
      "INFO:root:  Epoch 135/150\t Time: 0.062\t Loss: 0.00000038\n",
      "INFO:root:  Epoch 136/150\t Time: 0.062\t Loss: 0.00000067\n",
      "INFO:root:  Epoch 137/150\t Time: 0.062\t Loss: 0.00000099\n",
      "INFO:root:  Epoch 138/150\t Time: 0.065\t Loss: 0.00000039\n",
      "INFO:root:  Epoch 139/150\t Time: 0.063\t Loss: 0.00000044\n",
      "INFO:root:  Epoch 140/150\t Time: 0.064\t Loss: 0.00000068\n",
      "INFO:root:  Epoch 141/150\t Time: 0.066\t Loss: 0.00000084\n",
      "INFO:root:  Epoch 142/150\t Time: 0.063\t Loss: 0.00000062\n",
      "INFO:root:  Epoch 143/150\t Time: 0.066\t Loss: 0.00000054\n",
      "INFO:root:  Epoch 144/150\t Time: 0.063\t Loss: 0.00000089\n",
      "INFO:root:  Epoch 145/150\t Time: 0.063\t Loss: 0.00000034\n",
      "INFO:root:  Epoch 146/150\t Time: 0.064\t Loss: 0.00000050\n",
      "INFO:root:  Epoch 147/150\t Time: 0.063\t Loss: 0.00000065\n",
      "INFO:root:  Epoch 148/150\t Time: 0.061\t Loss: 0.00000050\n",
      "INFO:root:  Epoch 149/150\t Time: 0.064\t Loss: 0.00000060\n",
      "INFO:root:  Epoch 150/150\t Time: 0.063\t Loss: 0.00000051\n",
      "INFO:root:Training time: 9.693\n",
      "INFO:root:Finished training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "訓練完成。\n",
      "開始測試...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Starting testing...\n",
      "INFO:root:Testing time: 0.192\n",
      "INFO:root:Test set AUC: 84.16%\n",
      "INFO:root:Finished testing.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "測試完成。\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "logger = logging.getLogger()\n",
    "\n",
    "results, net, dataset = test_deep_svdd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hyperFeature(TrainTest):\n",
    "    net.eval()\n",
    "    train_loader, test_loader = dataset.loaders(batch_size=64, num_workers=0)\n",
    "    hyperFeature = []\n",
    "\n",
    "    if TrainTest == 'train':\n",
    "        loader = train_loader\n",
    "    else:\n",
    "        loader = test_loader\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            inputs, labels, idx = data\n",
    "            inputs = inputs.to('cuda')\n",
    "\n",
    "            # 找到你了 小調皮\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            hyperFeature.append(outputs.cpu().numpy())\n",
    "\n",
    "    hyperFeatureNP = np.vstack(hyperFeature)\n",
    "    return hyperFeatureNP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.10784657  0.12341575 -0.10008763 ... -0.11373153 -0.15216807\n",
      "  -0.09996864]\n",
      " [ 0.10781965  0.12341279 -0.10003429 ... -0.11374359 -0.15218966\n",
      "  -0.09998366]\n",
      " [ 0.10785884  0.1234149  -0.10005244 ... -0.11373006 -0.15216704\n",
      "  -0.09999226]\n",
      " ...\n",
      " [ 0.10782436  0.12340333 -0.10003003 ... -0.11374903 -0.1522008\n",
      "  -0.10000595]\n",
      " [ 0.10784461  0.1234183  -0.10004415 ... -0.1137274  -0.15219358\n",
      "  -0.10000332]\n",
      " [ 0.10784838  0.12341624 -0.10002169 ... -0.1136986  -0.15218185\n",
      "  -0.10001812]]\n",
      "[[ 0.10786185  0.12342545 -0.10000111 ... -0.11373256 -0.15219168\n",
      "  -0.10002408]\n",
      " [ 0.10789212  0.12343761 -0.09989023 ... -0.11358904 -0.15213484\n",
      "  -0.1000426 ]\n",
      " [ 0.11079861  0.12449244 -0.10390723 ... -0.11132355 -0.15107353\n",
      "  -0.09870771]\n",
      " ...\n",
      " [ 0.10788393  0.12342068 -0.09997612 ... -0.11363451 -0.15214022\n",
      "  -0.09997326]\n",
      " [ 0.10783868  0.12340797 -0.10002435 ... -0.11372442 -0.15219305\n",
      "  -0.10001335]\n",
      " [ 0.10787791  0.12340873 -0.09996599 ... -0.11366645 -0.15216586\n",
      "  -0.09999664]]\n"
     ]
    }
   ],
   "source": [
    "trainHF = get_hyperFeature('train')\n",
    "testHF = get_hyperFeature('test')\n",
    "\n",
    "print(trainHF)\n",
    "print(testHF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of detected anomalies: 11904\n",
      "AUC-ROC: 0.9415738090657289\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# Initialize the Isolation Forest model\n",
    "iso_forest = IsolationForest(contamination=0.1, random_state=42, n_estimators= 130, bootstrap=True, max_features=7)\n",
    "\n",
    "# Fit the model on the hyperFeatureNP data\n",
    "iso_forest.fit(trainHF)\n",
    "\n",
    "# Predict anomalies\n",
    "anomaly_scores = iso_forest.decision_function(testHF)\n",
    "anomalies = iso_forest.predict(testHF)\n",
    "\n",
    "# Convert predictions to binary labels (1 for normal, -1 for anomaly)\n",
    "anomalies = [1 if x == -1 else 0 for x in anomalies]\n",
    "\n",
    "# Print the number of detected anomalies\n",
    "print(f\"Number of detected anomalies: {sum(anomalies)}\")\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, precision_score\n",
    "# Calculate AUC-ROC\n",
    "\n",
    "y_true = []\n",
    "_, test_loader = dataset.loaders(batch_size=64, num_workers=0)\n",
    "for data in test_loader:\n",
    "    _, labels, _ = data\n",
    "    y_true.append(labels.cpu().numpy())\n",
    "\n",
    "y_true = np.hstack(y_true)\n",
    "\n",
    "auc_roc = roc_auc_score(y_true, -anomaly_scores)\n",
    "print(f\"AUC-ROC: {auc_roc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = {\n",
    "#     'n_estimators' : [10, 20 ,30, 40, 50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200],\n",
    "#     'bootstrap' : [True, False],\n",
    "#     'max_features' : [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_iter = 3000  # 設定測試次數\n",
    "# best_params = None\n",
    "# best_score = -np.inf\n",
    "# try:\n",
    "#     for i in range(n_iter):\n",
    "#         # 隨機選取參數\n",
    "#         params = {key: random.choice(values) for key, values in param_grid.items()}\n",
    "\n",
    "#         # 初始化模型\n",
    "#         iso_forest = IsolationForest(random_state=42, n_estimators=params['n_estimators'], bootstrap=params['bootstrap'], max_features=params['max_features'])\n",
    "\n",
    "#         # 訓練模型\n",
    "#         iso_forest.fit(trainHF)\n",
    "\n",
    "#         # 預測異常\n",
    "#         anomaly_scores = iso_forest.decision_function(testHF)\n",
    "\n",
    "#         # 計算 AUC-ROC\n",
    "#         auc_roc = roc_auc_score(y_true, -anomaly_scores)\n",
    "\n",
    "#         # 更新最佳參數\n",
    "#         if auc_roc > best_score:\n",
    "#             best_score = auc_roc\n",
    "#             best_params = params\n",
    "\n",
    "#         print(f\"Iteration {i+1}/{n_iter} - AUC-ROC: {auc_roc}\")\n",
    "\n",
    "#     print(f\"Best parameters: {best_params}\")\n",
    "#     print(f\"Best AUC-ROC: {best_score}\")\n",
    "\n",
    "# except KeyboardInterrupt:\n",
    "#     pass\n",
    "\n",
    "# # 輸出最佳結果\n",
    "# print(\"\\nBest Parameters:\", best_params)\n",
    "# print(\"Best ROC-AUC:\", best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainScore = iso_forest.decision_function(trainHF)\n",
    "\n",
    "threshold = np.percentile(trainScore, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08850499972646303"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholdAnomalies = []\n",
    "for i in range(len(anomaly_scores)):\n",
    "    if anomaly_scores[i] < threshold:\n",
    "        thresholdAnomalies.append(1)\n",
    "    else:\n",
    "        thresholdAnomalies.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "815"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholdAnomalies.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9453347207769685\n",
      "F1 Score: 0.9709589444976782\n",
      "Precision: 0.9686029411764706\n",
      "Recall: 0.973326437121324\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, thresholdAnomalies)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_true, thresholdAnomalies)\n",
    "\n",
    "precision = precision_score(y_true, thresholdAnomalies)\n",
    "\n",
    "recall = recall_score(y_true, thresholdAnomalies)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "# Assuming y_test and y_pred are defined\n",
    "# cm = confusion_matrix(y_true, thresholdAnomalies)\n",
    "\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "# disp.plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8741588622962192\n",
      "F1 Score: 0.9286893623712557\n",
      "Precision: 0.9922715053763441\n",
      "Recall: 0.8727648884291415\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, anomalies)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(y_true, anomalies)\n",
    "\n",
    "precision = precision_score(y_true, anomalies)\n",
    "\n",
    "recall = recall_score(y_true, anomalies)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib.colorbar:locator: <matplotlib.ticker.AutoLocator object at 0x00000215A3633FD0>\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming y_test and y_pred are defined\n",
    "cm = confusion_matrix(y_true, anomalies)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0, 1])\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = dataset.loaders(batch_size=64, num_workers=0)\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "for data in train_loader:\n",
    "    inputs, labels, idx = data\n",
    "    X_train.append(inputs.cpu().numpy())\n",
    "\n",
    "for data in test_loader:\n",
    "    inputs, labels, idx = data\n",
    "    X_test.append(inputs.cpu().numpy())\n",
    "    y_test.append(labels.cpu().numpy())\n",
    "\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.vstack(X_test)\n",
    "y_test = np.hstack(y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AnomalyDetectionMLGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
